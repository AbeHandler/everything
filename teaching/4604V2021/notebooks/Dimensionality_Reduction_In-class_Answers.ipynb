{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4604/5604 Dimensionality reduction \n",
    "\n",
    "- 11/18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'this', 'is', 'a', 'tokenizer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ptb import TreebankWordTokenizer\n",
    "\n",
    "tok = TreebankWordTokenizer()\n",
    "tok.tokenize(\"Hello this is a tokenizer\")  # experiment with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"gigaword10k.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the Gigaword corpus and tokenize it\n",
    "\n",
    "- What do you notice about how the tokenizer is forming tokens?\n",
    "- Can you suggest an improvement for this corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus, \"r\") as inf:\n",
    "    for doc in inf:\n",
    "        toks = tok.tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a vocabulary set $V$ consisting of the set of all words in the corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-2a49668b0c91>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for doc in tqdm(inf):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6375b8720e44433cb2ea7e593b84e69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "V = set()\n",
    "\n",
    "with open(corpus, \"r\") as inf:\n",
    "    for doc in tqdm(inf):\n",
    "        toks = tok.tokenize(doc)\n",
    "        for t in toks:\n",
    "            V.add(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of documents in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-6228f241e156>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for doc in tqdm(inf):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960003e04f164d75b9b3d11220f87288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "D = 0\n",
    "\n",
    "with open(corpus, \"r\") as inf:\n",
    "    for doc in tqdm(inf):\n",
    "        D += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map each word to a number, and each number to a word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2n = {}\n",
    "for vno, v in enumerate(V):\n",
    "    word2n[v] = vno\n",
    "    \n",
    "n2word = {v: k for k, v in word2n.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What number corresponds to the word \"soccer\"? \n",
    "- What word corresponds to the number 17?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a term-document matrix\n",
    "\n",
    "- You should create a matrix that is D by V. \n",
    "- There should be a 1 if a word occurs in a given document. Otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c251078846a1>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for dno, doc in tqdm(enumerate(inf)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05a5694c3944c849b542db5b3b9f731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tdm = np.zeros((D, len(V)))\n",
    "\n",
    "with open(corpus, \"r\") as inf:\n",
    "    for dno, doc in tqdm(enumerate(inf)):\n",
    "        for v in tok.tokenize(doc):\n",
    "            tdm[dno][word2n[v]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the term-document matrix \n",
    "\n",
    "- How many rows does it have?\n",
    "- How many columns does it have?\n",
    "- What are the dimensions of the term-document matrix? \n",
    "- Do those numbers make sense?\n",
    "- Use the matrix to determine which words are in the 14th document in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdmT = tdm.T  # transpose the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What do the rows represent now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA \n",
    "\n",
    "Use the sklearn implementation of PCA to reduce the dimensionality of the transposed term document matrix\n",
    "- Set `n_components=15` to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import ipdb\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "print(\"ok\")\n",
    "pca = PCA(n_components=15, svd_solver=\"randomized\")\n",
    "pca.fit(word_doc)\n",
    "print(\"don\")\n",
    "\n",
    "low_dim = pca.transform(tdmT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Questions \n",
    "\n",
    "- How many rows and columns are in the low-dimensional representation? \n",
    "- What do the rows represent? \n",
    "- What do the columns represent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions \n",
    "\n",
    "- Print out the low dimensional matrix. What do you notice about the rows, as compared to the term-document matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookups\n",
    "\n",
    "- Use a [KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html) to make a data structure for looking up words\n",
    "- Look up the 10 words closest to \"sports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "don\n",
      "sports\n",
      "longest-serving\n",
      "basketball\n",
      "communities\n",
      "zaire\n",
      "standing\n",
      "drought\n",
      "olympics\n",
      "holds\n",
      "farm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "kdt = KDTree(low_dim, leaf_size=200, metric='euclidean')\n",
    "\n",
    "pickle.dump(low_dim, open(\"low_dim.r\", \"wb\"))\n",
    "pickle.dump(kdt, open(\"vecs.r\", \"wb\"))\n",
    "\n",
    "kdt = pickle.load(open(\"vecs.r\", \"rb\"))\n",
    "low_dim = pickle.load(open(\"low_dim.r\", \"rb\"))\n",
    "\n",
    "# sports\n",
    "pt_1 = low_dim[word2n[\"sports\"]]\n",
    "\n",
    "answers = kdt.query(pt_1.reshape(1, -1), k=10)\n",
    "\n",
    "for d in answers[1]:\n",
    "    for c in d:\n",
    "        print(n2word[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tuning \n",
    "\n",
    "- What happens if you vary `n_components` in terms of compute time?\n",
    "- What happens if you vary `n_components` in terms of vector quality?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
