{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with unstructured data (Module 07)\n",
    "\n",
    "\n",
    "- A huge area. We will just scratch the surface.\n",
    "- We will focus on text, but this also applies to images, audio data, some sensor data ...  \n",
    "- I first heard about this area ~7 years ago and was very excited. I think it is a little more common these days? \n",
    "- Why text? People interact with each other through language, so computational text analysis is a neat way to combine interests in computers & human society.\n",
    "- Jargon: \"natural language processing,\" \"computational linguistics,\" \"text as data,\" \"NLP+CSS.\" These things have slightly different meanings, but there is a lot of overlap.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "If six 50-minute sessions working with text data is not enough for you, there are many ways to keep going with it.\n",
    "\n",
    "- Courses:\n",
    "    - [LING 1200](https://catalog.colorado.edu/courses-a-z/ling/) (cross listed with INFO)\n",
    "    - [MS degree at CU](https://www.colorado.edu/linguistics/graduate-program/computational-linguistics-clasic-ms)\n",
    "\n",
    "\n",
    "- Books: \n",
    "    - [Intro to Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf) (Available as hardback, or use the linked PDF off GitHub.)\n",
    "    - [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/) (Older text book, still good. You can find PDFs online.)\n",
    "    \n",
    "    \n",
    "- Conferences:\n",
    "    - [Text as data](https://www.textasdata2019.net/) (Political science + computer science)\n",
    "    - [CS + J](http://cplusj.org/) (Not strictly for text, but comes up a lot)\n",
    "    - [*CL](http://aclweb.org/) (Umbrella org for conferences focused on computers + text, aka \"natural langauge processing\")\n",
    "    - [#NLProc](https://twitter.com/hashtag/nlproc?lang=en) (A group of very knowledgeable researchers and practitioners talk about this stuff all day on Twitter. If you want to keep up with the latest and greatest, this is a good way to do so.)\n",
    "    \n",
    "\n",
    "- Software:\n",
    "    - [NLTK](https://github.com/nltk/nltk) Very popular software for NLP in Python. Common entry into NLP.\n",
    "    - [Spacy](https://spacy.io/) Another popular Python NLP library. Way more performant than NLTK, and perhaps better maintained. \n",
    "    - [Hugging Face](https://github.com/huggingface) New NLP library focused on specific kinds of neural networks that are very popular. You might find this one hard to work with, but good to know about.\n",
    "    - [AllenNLP](https://allennlp.org/) Another new-ish one that is good to just be aware of. More focused on research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured vs. unstructured data\n",
    "\n",
    "Examples:\n",
    "- [Structured](https://github.com/nytimes/covid-19-data/blob/master/us.csv)\n",
    "- [Unstructured](https://www.reddit.com/r/cuboulder/)\n",
    "\n",
    "Questions:\n",
    "- What is the difference between structured and unstructured?\n",
    "- What are other examples of unstructured data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text step 1: Tokenization \n",
    "\n",
    "- Text usually starts as a string of characters\n",
    "- We need to take that string of characters and turn it into a list of words\n",
    "- Tokenization is the process of doing so\n",
    "- _Sorry, 4604 students. Everyone needs to know this. It is the first step in most NLP pipelines._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ca', \"n't\", 'go', 'outside']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ptb import TreebankWordTokenizer\n",
    "# This is the Penn Tree Bank tokenizer from NLTK as just one file\n",
    "tok = TreebankWordTokenizer()\n",
    "tok.tokenize(\"Hello this is a tokenizer\")\n",
    "\n",
    "tok.tokenize(\"I can't go outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "    \n",
    "- How is this different than split (h/t Jay) \n",
    "- Why do you think it might make sense to split \"can't\" into \"ca,\" \"n't\"? What information does this give to a dumb computer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
