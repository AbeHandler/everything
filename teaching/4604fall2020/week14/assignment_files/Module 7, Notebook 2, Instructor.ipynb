{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with unstructured data (Module 07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import TreebankWordTokenizer\n",
    "# This is the Penn Tree Bank tokenizer from NLTK as just one file\n",
    "tok = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a covariate\n",
    "\n",
    "- In text processing, a variable that occurs along with words (but is not a word) is sometimes called a covariate \n",
    "\n",
    "- This is similar to the idea of \"metadata\"\n",
    "\n",
    "- Example covariates: day of the week, time of day, number of upvotes, author, political party "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Make a term document matrix for `libertarian.jsonl`\n",
    "- Make a term document matrix for `socialism.jsonl`\n",
    "- This is mostly review from last time, but you should share the vocabulary across the two subreddits\n",
    "- There are two changes since last time... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change 1: Raw counts \n",
    "\n",
    "- Last time we made a binary matrix. This was just to get started.\n",
    "- This time, instead of a binary matrix, replace the 1s with the counts of each word\n",
    "- So if a word occurs 5x in a document, the number should be 5 in the term-document matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change 2: Stop words \n",
    "\n",
    "Before we start, we will add one new thing, stop words. A stop word is a common word that is excluded from analysis in text processing. In NLP, it is common to exclude stop words. There are many stop word lists out there. We will use a [common list](https://gist.github.com/sebleier/554280) from NLTK. \n",
    "\n",
    "Start off by downloading the list using requests. Hint: click raw on Github to get a link to the raw data.\n",
    "\n",
    "Once you had a stop word list, when you read in the tokens from your file, this time ignore the stop words. Lower case the word to see if it is a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import string\n",
    "\n",
    "url = \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\"\n",
    "r = requests.get(url).text\n",
    "stop_words = r.split(\"\\n\")\n",
    "stop_words = [i.lower() for i in stop_words] + [o for o in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_D_and_V(fn):\n",
    "    V = set()\n",
    "    D = 0\n",
    "\n",
    "    with open(fn, \"r\") as inf:\n",
    "        for doc in inf:\n",
    "            D += 1\n",
    "            doc = json.loads(doc)\n",
    "            for token in tok.tokenize(doc[\"body\"]):\n",
    "                if token.lower() not in stop_words:\n",
    "                    V.add(token)\n",
    "\n",
    "    V = list(V) # we want a consistent order. Not sure the latest on Python set ordering\n",
    "    \n",
    "    return D, V\n",
    "\n",
    "D1, V1 = get_D_and_V(fn=\"libertarian.jsonl\")\n",
    "D2, V2 = get_D_and_V(fn=\"socialism.jsonl\")\n",
    "\n",
    "V = list(set(V1 + V2))\n",
    "\n",
    "n2v = {k:v for k, v in enumerate(V)}\n",
    "v2n = {v:k for k, v in enumerate(V)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a tdm for each subreddit, sharing vocabulary\n",
    "- Remember to skip stop words\n",
    "- Remember to make a matrix of counts, not a binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_tdm(_D, _V, fn):\n",
    "\n",
    "    out = np.zeros((D2, len(_V)))\n",
    "\n",
    "    with open(fn, \"r\") as inf:\n",
    "        for docno, doc in enumerate(inf):\n",
    "            doc = json.loads(doc)\n",
    "            for token in tok.tokenize(doc[\"body\"]):\n",
    "                if token.lower() not in stop_words:\n",
    "                    out[docno][v2n[token]] += 1\n",
    "\n",
    "    out = pd.DataFrame(data=out, columns=V)\n",
    "    \n",
    "    return out\n",
    "\n",
    "tdm_libertarian_df =  make_tdm(D1, V, fn=\"libertarian.jsonl\")\n",
    "tdm_socialism_df =  make_tdm(D2, V, fn=\"socialism.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add in covariates, and make a big dataframe\n",
    "\n",
    "tdm_libertarian_df[\"source_reddit\"] = \"libertarian\"\n",
    "tdm_socialism_df[\"source_reddit\"] = \"socialism\"\n",
    "\n",
    "tdm = pd.concat([tdm_libertarian_df, tdm_socialism_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "- What does the tdm represent, now that we added the `source_reddit` covariate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "- What are the top terms, based on raw count in the libertarian subreddit?\n",
    "- What are the top terms, based on raw count in the socialism subreddit?\n",
    "- Do you think it helps that you removed stop words?\n",
    "- Can you think of ways to expand the stop word list that might help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n't</th>\n",
       "      <td>5185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>4784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>2707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>2613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>2394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transference</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epitome</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>**man**^</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backhoe</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incursion</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              frequency\n",
       "n't              5185.0\n",
       "'s               4784.0\n",
       "people           2707.0\n",
       "''               2613.0\n",
       "``               2394.0\n",
       "...                 ...\n",
       "transference        0.0\n",
       "epitome             0.0\n",
       "**man**^            0.0\n",
       "backhoe             0.0\n",
       "incursion           0.0\n",
       "\n",
       "[51460 rows x 1 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_socialism = tdm[tdm[\"source_reddit\"] == \"socialism\"]\n",
    "counts_socialism = counts_socialism.drop(columns=[\"source_reddit\"], axis=1)\n",
    "counts_socialism = counts_socialism.sum(axis=0)\n",
    "counts_socialism = pd.DataFrame(counts_socialism)\n",
    "counts_socialism = counts_socialism.rename(columns={0: \"frequency\"})\n",
    "counts_socialism.sort_values(by=\"frequency\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n't</th>\n",
       "      <td>4617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'s</th>\n",
       "      <td>4290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>2607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>2606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>``</th>\n",
       "      <td>2316.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percieve</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>circlejerking</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medlem</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>determinism.</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000's.</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               frequency\n",
       "n't               4617.0\n",
       "'s                4290.0\n",
       "gt                2607.0\n",
       "''                2606.0\n",
       "``                2316.0\n",
       "...                  ...\n",
       "percieve             0.0\n",
       "circlejerking        0.0\n",
       "medlem               0.0\n",
       "determinism.         0.0\n",
       "2000's.              0.0\n",
       "\n",
       "[51460 rows x 1 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_libertarian = tdm[tdm[\"source_reddit\"] == \"libertarian\"]\n",
    "counts_libertarian = counts_libertarian.drop(columns=[\"source_reddit\"], axis=1)\n",
    "counts_libertarian = counts_libertarian.sum(axis=0)\n",
    "counts_libertarian = pd.DataFrame(counts_libertarian)\n",
    "counts_libertarian = counts_libertarian.rename(columns={0: \"frequency\"})\n",
    "counts_libertarian.sort_values(by=\"frequency\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf\n",
    "\n",
    "- Intuition: if a word is common, then a high frequency is not so meaningful.\n",
    "- The fact that \"because\" shows up a lot in the libertarian subreddit is not that important\n",
    "- In text processing, it is common to discount word scores by 1 divided by the number of documents where the word occurs\n",
    "- We can build some intuition for this on the whiteboard\n",
    "- For our purposes, we will define the inverse document frequency as 1/Dw, where Dw is the count of documents that contain a word across the whole corpus (both reddits)\n",
    "- If 10 documents contain the word \"#jurynullification\" what is Dw for \"#jurynullification\"?\n",
    "- What do you think the Dw for \"because\" would be?\n",
    "- To get a tf-idf score we multiply the term frequency (tf) by the idf score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute idf \n",
    "\n",
    "- Compute the idf for each word from the TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = np.sum(tdm.drop([\"source_reddit\"], axis=1)> 0)\n",
    "D = tdm.shape[0]\n",
    "idf = pd.DataFrame({\"idf\": 1/mx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute tf-idf scores\n",
    "\n",
    "- Compute tf-idf scores for each word from the TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_libertarian[\"tfidf\"] = counts_libertarian[\"frequency\"] * idf[\"idf\"]\n",
    "counts_socialism[\"tfidf\"] = counts_socialism[\"frequency\"] * idf[\"idf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling rare words \n",
    "\n",
    "- tf-idf and other metrics tend to boost word importance scores for rare words (why?)\n",
    "- One way to do this is to ignore words that only occur in only 1 or 2 documents \n",
    "- Modify your code to ignore rare words\n",
    "- There are a few ways to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf[idf[\"idf\"] > .25] = 0\n",
    "counts_libertarian[\"tfidf\"] = counts_libertarian[\"frequency\"] * idf[\"idf\"]\n",
    "counts_socialism[\"tfidf\"] = counts_socialism[\"frequency\"] * idf[\"idf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mr', 'feat.', 'Turkish', 'hip', 'Trots', 'ft.', 'hop.', 'Poland',\n",
       "       'Bookchin', 'EU', 'Harvey', 'cites', 'Community', 'absentee', 'Kliman',\n",
       "       'Bolivar', 'Rosa', 'deed', 'Proudhon', 'Berlin', 'bourgeosie', 'coca',\n",
       "       'Proyect', 'hop', 'Bioshock', 'FARC', 'LTRPF', 'er', 'stereotypes',\n",
       "       'Hamas', 'Eurozone', 'moneyless', 'intrinsically', 'Costs', 'Rise',\n",
       "       'Verso', 'Tijoux', 'soc', 'Buddhist', 'marxists', 'delusions',\n",
       "       'left-liberal', 'Scottish', 'WSWS', 'Technique', 'Immortal', 'Cuban',\n",
       "       'Labour', 'Yugoslavia', 'Guevara', 'rap', 'parliaments', 'IRC', 'Venus',\n",
       "       'editors', 'battalion', 'uncompromising', 'Alice', 'tribalism', 'USSR.',\n",
       "       'obesity', 'vouchers', 'Cuba', 'organising', 'NATO', 'blah', 'Marxism',\n",
       "       'innovation.', 'Vox', 'PKK', 'halls', 'accumulate', 'Comunista',\n",
       "       'Reconstrucción', 'patriarchal', 'comfort/entertainment', 'achievable',\n",
       "       'Ana', 'Feminists', 'deficit', 'Mos', 'rewarding', 'Lupe', 'Buddhism',\n",
       "       'Socialized', 'programming', 'music.', 'Bangladesh', 'Raul', 'Batista',\n",
       "       'stalinist', 'unity.', 'orthodox', 'electronic', 'Organizing', 'Volume',\n",
       "       'social-democratic', 'copyrights', 'novels', 'Havana'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_socialism.sort_values(\"tfidf\", ascending=False)[0:100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^|', 'Nexium', 'quot', 'hijackers', 'mg', '009', 'ESA', 'glasses',\n",
       "       'Prilosec', 'Gilded', 'NRA', 'passengers', 'temp', 'amp', 'DNA',\n",
       "       'airlines', '039', 'incestuous', '/message/compose', 'to=autowikibot',\n",
       "       'Conley', 'WTC', '^or', 'OTC', 'incest', 'message=', '^delete',\n",
       "       'subject=AutoWikibot', 'herd', 'stickers', 'FISA', 'prescription',\n",
       "       '*****', 'soda', 'ID', 'sorority', 'Barr', '^libertarianism', 'FICA',\n",
       "       '2F', 'MJ', 'elective', '^of', 'encryption', 'plane.', 'Gardner',\n",
       "       'exchanges', 'tl', '//en.wikipedia.org/wiki/Libertarianism', 'refund',\n",
       "       'charter', 'sexuality.', 'heroin', 'Musk', 'temps', 'Pentagon',\n",
       "       'marriage', 'lenses', 'airline', 'GM', 'planes', 'Kasich',\n",
       "       'announcement', 'Air', 'Towers', 'nihilist', 'nuisance', 'vaccination',\n",
       "       'Flight', 'statute', 'Biden', 'blah', '10th', 'standard.', 'resolved',\n",
       "       '14th', 'evaluating', 'dwelling', 'SWAT', 'joints', 'Josh', 'weed.',\n",
       "       'encrypted', 'Richmond', 'premiums', 'reporters', 'plane', 'deputy',\n",
       "       'Medicaid', 'keys', 'Surveillance', 'Singapore', 'molestation',\n",
       "       'Jonathan', 'NAP', 'searches', 'Chelsea', 'mouthing', 'customs',\n",
       "       'sighted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_libertarian.sort_values(\"tfidf\", ascending=False)[0:100].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing raw counts w/ tf-idf\n",
    "\n",
    "- Compare the raw counts with the tf-idf scaled words\n",
    "- Which seems to do a better job capturing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrases \n",
    "\n",
    "- If we have time, we can consider how to redo this analysis using phrases \n",
    "- Why might we want to do that? \n",
    "- Some [software](https://github.com/slanglab/phrasemachine) for this..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
