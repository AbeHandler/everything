{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with unstructured data (Module 07)\n",
    "\n",
    "\n",
    "- A huge area. We will just scratch the surface.\n",
    "- We will focus on text, but this also applies to images, audio data, some sensor data ...  \n",
    "- I first heard about this area ~7 years ago and was very excited. I think it is a little more common these days? \n",
    "- Why text? People interact with each other through language, so computational text analysis is a neat way to combine interests in computers & human society.\n",
    "- Jargon: \"natural language processing,\" \"computational linguistics,\" \"text as data,\" \"NLP+CSS.\" These things have slightly different meanings, but there is a lot of overlap.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "If six 50-minute sessions working with text data is not enough for you, there are many ways to keep going with it.\n",
    "\n",
    "- Courses:\n",
    "    - [LING 1200](https://catalog.colorado.edu/courses-a-z/ling/) (cross listed with INFO)\n",
    "    - [MS degree at CU](https://www.colorado.edu/linguistics/graduate-program/computational-linguistics-clasic-ms)\n",
    "\n",
    "\n",
    "- Books: \n",
    "    - [Intro to Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf) (Available as hardback, or use the linked PDF off GitHub.)\n",
    "    - [Foundations of Statistical Natural Language Processing](https://nlp.stanford.edu/fsnlp/) (Older text book, still good. You can find PDFs online.)\n",
    "    \n",
    "    \n",
    "- Conferences:\n",
    "    - [Text as data](https://www.textasdata2019.net/) (Political science + computer science)\n",
    "    - [CS + J](http://cplusj.org/) (Not strictly for text, but comes up a lot)\n",
    "    - [*CL](http://aclweb.org/) (Umbrella org for conferences focused on computers + text, aka \"natural langauge processing\")\n",
    "    - [#NLProc](https://twitter.com/hashtag/nlproc?lang=en) (A group of very knowledgeable researchers and practitioners talk about this stuff all day on Twitter. If you want to keep up with the latest and greatest, this is a good way to do so.)\n",
    "    \n",
    "\n",
    "- Software:\n",
    "    - [NLTK](https://github.com/nltk/nltk) Very popular software for NLP in Python. Common entry into NLP.\n",
    "    - [Spacy](https://spacy.io/) Another popular Python NLP library. Way more performant than NLTK, and perhaps better maintained. \n",
    "    - [Hugging Face](https://github.com/huggingface) New NLP library focused on specific kinds of neural networks that are very popular. You might find this one hard to work with, but good to know about.\n",
    "    - [AllenNLP](https://allennlp.org/) Another new-ish one that is good to just be aware of. More focused on research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured vs. unstructured data\n",
    "\n",
    "Examples:\n",
    "- [Structured](https://github.com/nytimes/covid-19-data/blob/master/us.csv)\n",
    "- [Unstructured](https://www.reddit.com/r/cuboulder/)\n",
    "\n",
    "Questions:\n",
    "- What is the difference between structured and unstructured?\n",
    "- What are other examples of unstructured data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text step 1: Tokenization \n",
    "\n",
    "- Text usually starts as a string of characters\n",
    "- We need to take that string of characters and turn it into a list of words\n",
    "- Tokenization is the process of doing so\n",
    "- _Sorry, 4604 students. Everyone needs to know this. It is the first step in most NLP pipelines. There is a little overlap here w/ recent 4604 classes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'ca', \"n't\", 'go', 'outside']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ptb import TreebankWordTokenizer\n",
    "# This is the Penn Tree Bank tokenizer from NLTK as just one file\n",
    "tok = TreebankWordTokenizer()\n",
    "tok.tokenize(\"Hello this is a tokenizer\")\n",
    "\n",
    "tok.tokenize(\"I can't go outside\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "    \n",
    "- How is this different than split (h/t Jay) \n",
    "- Why do you think it might make sense to split \"can't\" into \"ca,\" \"n't\"? What information does this give to a computer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "    \n",
    "- Read in `dogs10k.jsonl`. Access the `body` field. This is cleaned up data from the pushift API\n",
    "\n",
    "- Why is this unstructured data?\n",
    "\n",
    "- Can you figure out how to find the post from the data on reddit? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions: \n",
    "    \n",
    "- Tokenize the body of each post on `dogs10k.jsonl` to create a vocabulary set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "V = set()  # Set of all words that occur in the documents\n",
    "D = 0      # Document count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Questions: \n",
    "    \n",
    "- What is D?\n",
    "- What is V?\n",
    "- Is D bigger than V? \n",
    "- If we increased the size of the dataset, would D or V increase faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 A\n",
      "1 B\n",
      "2 C\n"
     ]
    }
   ],
   "source": [
    "# understanding enumerate\n",
    "\n",
    "for docno, doc in enumerate([\"A\", \"B\", \"C\"]):\n",
    "    print(docno, doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numberization\n",
    "\n",
    "- A great word\n",
    "- Turning words into numbers\n",
    "- This is honestly a mind-bender\n",
    "- Pause for a minute here. We are going from words to numbers.\n",
    "- When we use numbers, we can use tools from math to reason about words. \n",
    "- Pause. Breathe.\n",
    "- [Cool book](https://web.stanford.edu/group/cslipublications/cslipublications/site/1575864487.shtml) about this. It's a big conceptual leap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping words to numbers and back\n",
    "\n",
    "for docno, doc in enumerate([\"A\", \"B\", \"C\"]):\n",
    "    print(docno, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the mapping\n",
    "\n",
    "v2n = {}   # Map each word to a number \n",
    "n2v = {}   # Map the number back to a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions \n",
    "\n",
    "- What is n2v for \"fetch\"\n",
    "- What is v2n for 15?\n",
    "- How many times does each word occur in $V$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary term-document matrix \n",
    "\n",
    "We will do this on a whiteboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a binary term document matrix\n",
    "# The rows are documents, ths columns are words \n",
    "# The column is set to 1 if the word occurs in the document\n",
    "\n",
    "tdm = np.zeros((D, len(V)))\n",
    "\n",
    "# pass\n",
    "\n",
    "tdm_df = pd.DataFrame(data=tdm, columns=V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsity \n",
    "\n",
    "- What do you notice about each row of `tdm_df`? (hint: remember our friend iloc)\n",
    "\n",
    "- What do you notice about each column of `tdm_df`?\n",
    "\n",
    "- Why does this make sense?\n",
    "\n",
    "- This is a *fundamental* property of text data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete vs. continuous \n",
    "\n",
    "- Are these rows and columns discrete or continuous? \n",
    "- This is a *fundamental* property of text data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review\n",
    "\n",
    "- What are two fundamental properties of text data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most common words, least common words\n",
    "\n",
    "- What are the 10 most common words? What do you notice? \n",
    "\n",
    "- What are the 10 least common words? What do you notice? \n",
    "\n",
    "- Do you think the most common words would also be common in a subreddit about cats?\n",
    "\n",
    "- We will test this shortly. Data is up on Canvas\n",
    "\n",
    "- Which words do you think would be more common in a subreddit about dogs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_totals = None #  Count each time a word occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least common words that occur at least 5 times \n",
    "\n",
    "What are the 10 least common words? What do you notice? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability \n",
    "\n",
    "- Think all the way back to 2301\n",
    "- What if each word is an event?\n",
    "- What is the probability of observing the word \"frisbee\"?\n",
    "- Do you think it will be high or low? \n",
    "- More sparsity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipf's law \n",
    "\n",
    "- In the 1930s the linguist George Zipf noticed a relationship between the frequency of a word, and its rank (e.g. 3rd most common, 10th most common) in a corpus\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Zipf%27s_law) page has more\n",
    "\n",
    "- The frequency of a word is inversely proportional to its rank\n",
    "\n",
    "- You can predict the frequency of a word in a corpus based on its rank. The most frequent word is some factor more frequent than the next most frequent word which is some factor more frequent than the next most frequent word, and so on.\n",
    "\n",
    "- Let's test Zipf's law on our Reddit dogs data set. We will start with an informal, non-log scaled plot\n",
    "\n",
    "- If you want to do a more formal test, you can work from the Wikipedia page. \n",
    "- Measure the average square root of the squared deviation from the prediction. It would be a good exercise. Email me your code for extra credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame where the index is the rank of a word \n",
    "# The frequency of the word is stored is stored in a column called frequency\n",
    "\n",
    "# Then plot the frequencies. \n",
    "\n",
    "# Try setting logx and logy to true with pandas to make a logscaled plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions \n",
    "\n",
    "- How does this plot relate to sparisity? \n",
    "- Where do you think you would find the word \"the\" on this plot?\n",
    "- Where do you think you would find the word \"pitbull\"?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
